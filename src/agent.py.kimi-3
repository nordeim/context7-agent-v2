import os
from typing import Optional, List, Dict, Any
import logging

from pydantic_ai import Agent
from pydantic_ai.mcp import MCPServerStdio
from pydantic_ai.models.openai import OpenAIModel
from pydantic_ai.providers.openai import OpenAIProvider

from .config import Config
from .history import HistoryManager

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class Context7Agent:
    """
    Production-ready AI agent implementing a robust RAG pattern, deeply integrated with Context7 MCP.
    All chat and tool-calling happens via agent.run(), enforcing strict RAG: answers ONLY from retrieved context.
    """

    def __init__(self, config: Optional[Config] = None):
        config = config or Config.load()
        self.config = config

        # Provider
        self.provider = OpenAIProvider(
            api_key=config.openai_api_key,
            base_url=config.openai_base_url,
        )

        # Model - ensure it's a string
        self.model = OpenAIModel(
            model_name=str(config.openai_model),
            provider=self.provider,
        )

        # Agent - MCP servers will be attached at runtime
        self.agent = Agent(
            model=self.model,
            system_prompt=config.rag_system_prompt
        )

        # History manager
        self.history = HistoryManager(filepath=config.history_file)

    async def initialize(self):
        """Load persisted history and prepare agent."""
        try:
            await self.history.load_async()
            logger.info("Agent initialized successfully")
        except Exception as e:
            logger.error(f"Failed to load history: {e}")
            raise

    def create_mcp_server(self) -> MCPServerStdio:
        """Create MCP server with proper error handling."""
        import shutil
        
        npx_path = shutil.which("npx")
        if not npx_path:
            raise RuntimeError(
                "npx not found in PATH. Please install Node.js 18+ and ensure npm is available."
            )
        
        return MCPServerStdio(
            command=npx_path,
            args=["-y", "@upstash/context7-mcp@latest"],
            env=os.environ
        )

    async def chat(
        self, user_text: str, message_history: Optional[List[Dict]] = None
    ) -> str:
        """
        Processes a user query via the unified agent.run() method.
        MCP server lifecycle is managed internally for each call.
        """
        if not user_text.strip():
            return "I didn't receive any input. Please try again."

        message_history = message_history or []
        
        try:
            mcp_server = self.create_mcp_server()
            
            # ✅ CORRECT: Use keyword argument for mcp_servers
            async with self.agent.run_mcp_servers(mcp_servers=[mcp_server]):
                logger.debug(f"Processing query: {user_text}")
                result = await self.agent.run(user_text, message_history=message_history)
                return str(result.data)
                
        except Exception as e:
            logger.error(f"Chat error: {e}")
            return f"I encountered an error: {str(e)}. Please check your configuration and try again."

    async def chat_stream(
        self, user_text: str, message_history: Optional[List[Dict]] = None
    ):
        """
        Streams the chat response (for live/animated UI).
        MCP server lifecycle is managed internally for each call.
        """
        if not user_text.strip():
            yield "I didn't receive any input. Please try again."
            return

        message_history = message_history or []
        
        try:
            mcp_server = self.create_mcp_server()
            
            # ✅ CORRECT: Use keyword argument for mcp_servers
            async with self.agent.run_mcp_servers(mcp_servers=[mcp_server]):
                logger.debug(f"Streaming query: {user_text}")
                async for chunk in self.agent.run_stream(user_text, message_history=message_history):
                    yield chunk
                    
        except Exception as e:
            logger.error(f"Streaming error: {e}")
            yield f"Streaming error: {str(e)}"

    def get_history(self):
        """Get conversation history."""
        return self.history.history

    async def save_history(self):
        """Save conversation history."""
        try:
            await self.history.save_async()
            logger.info("History saved successfully")
        except Exception as e:
            logger.error(f"Failed to save history: {e}")
            raise
